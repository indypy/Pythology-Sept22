{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Maching Learning Preparation\n",
    "===\n",
    "\n",
    "* Create training, testing, and validation datasets\n",
    "* Data preprocessing\n",
    "* Select the best information to give to the algorithm\n",
    "* Select a machine learning algorithm for your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Set Up The Notebook\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interview/Exam</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Exam Completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5533.0</td>\n",
       "      <td>5533.000000</td>\n",
       "      <td>5533.000000</td>\n",
       "      <td>5533.000000</td>\n",
       "      <td>5533.000000</td>\n",
       "      <td>5533.000000</td>\n",
       "      <td>5533.000000</td>\n",
       "      <td>5533.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.518887</td>\n",
       "      <td>39.959154</td>\n",
       "      <td>1.798663</td>\n",
       "      <td>3.036689</td>\n",
       "      <td>75.864887</td>\n",
       "      <td>166.629966</td>\n",
       "      <td>1.006145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499688</td>\n",
       "      <td>21.953308</td>\n",
       "      <td>0.899678</td>\n",
       "      <td>1.911148</td>\n",
       "      <td>19.939066</td>\n",
       "      <td>9.816356</td>\n",
       "      <td>0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>119.800000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.740000</td>\n",
       "      <td>159.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>72.940000</td>\n",
       "      <td>166.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>86.400000</td>\n",
       "      <td>173.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>193.300000</td>\n",
       "      <td>201.300000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Interview/Exam       Gender          Age    Education  Marital Status  \\\n",
       "count          5533.0  5533.000000  5533.000000  5533.000000     5533.000000   \n",
       "mean              2.0     1.518887    39.959154     1.798663        3.036689   \n",
       "std               0.0     0.499688    21.953308     0.899678        1.911148   \n",
       "min               2.0     1.000000    14.000000     1.000000        1.000000   \n",
       "25%               2.0     1.000000    19.000000     1.000000        1.000000   \n",
       "50%               2.0     2.000000    36.000000     1.000000        3.000000   \n",
       "75%               2.0     2.000000    60.000000     3.000000        5.000000   \n",
       "max               2.0     2.000000    85.000000     5.000000        6.000000   \n",
       "\n",
       "       Weight (kg)  Height (cm)  Exam Completion  \n",
       "count  5533.000000  5533.000000      5533.000000  \n",
       "mean     75.864887   166.629966         1.006145  \n",
       "std      19.939066     9.816356         0.078156  \n",
       "min      25.600000   119.800000         1.000000  \n",
       "25%      61.740000   159.500000         1.000000  \n",
       "50%      72.940000   166.300000         1.000000  \n",
       "75%      86.400000   173.500000         1.000000  \n",
       "max     193.300000   201.300000         2.000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dataset = pd.read_csv('Data/CleanedDataset.csv', index_col=0)\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Choose our problem\n",
    "===\n",
    "\n",
    "We need a target value and features.\n",
    "* Target: Height (cm)\n",
    "* Features: Interview/Exam, Gender, Age, Education, Marital Status, Weight (kg), Exam Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5533.000000\n",
       "mean      166.629966\n",
       "std         9.816356\n",
       "min       119.800000\n",
       "25%       159.500000\n",
       "50%       166.300000\n",
       "75%       173.500000\n",
       "max       201.300000\n",
       "Name: Height (cm), dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interview/Exam</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Exam Completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5533.0</td>\n",
       "      <td>5533.000000</td>\n",
       "      <td>5533.000000</td>\n",
       "      <td>5533.000000</td>\n",
       "      <td>5533.000000</td>\n",
       "      <td>5533.000000</td>\n",
       "      <td>5533.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.518887</td>\n",
       "      <td>39.959154</td>\n",
       "      <td>1.798663</td>\n",
       "      <td>3.036689</td>\n",
       "      <td>75.864887</td>\n",
       "      <td>1.006145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499688</td>\n",
       "      <td>21.953308</td>\n",
       "      <td>0.899678</td>\n",
       "      <td>1.911148</td>\n",
       "      <td>19.939066</td>\n",
       "      <td>0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.740000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>72.940000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>86.400000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>193.300000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Interview/Exam       Gender          Age    Education  Marital Status  \\\n",
       "count          5533.0  5533.000000  5533.000000  5533.000000     5533.000000   \n",
       "mean              2.0     1.518887    39.959154     1.798663        3.036689   \n",
       "std               0.0     0.499688    21.953308     0.899678        1.911148   \n",
       "min               2.0     1.000000    14.000000     1.000000        1.000000   \n",
       "25%               2.0     1.000000    19.000000     1.000000        1.000000   \n",
       "50%               2.0     2.000000    36.000000     1.000000        3.000000   \n",
       "75%               2.0     2.000000    60.000000     3.000000        5.000000   \n",
       "max               2.0     2.000000    85.000000     5.000000        6.000000   \n",
       "\n",
       "       Weight (kg)  Exam Completion  \n",
       "count  5533.000000      5533.000000  \n",
       "mean     75.864887         1.006145  \n",
       "std      19.939066         0.078156  \n",
       "min      25.600000         1.000000  \n",
       "25%      61.740000         1.000000  \n",
       "50%      72.940000         1.000000  \n",
       "75%      86.400000         1.000000  \n",
       "max     193.300000         2.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interview/Exam</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Exam Completion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>59.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>99.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Interview/Exam  Gender   Age  Education  Marital Status  Weight (kg)  \\\n",
       "ID                                                                         \n",
       "5              2.0     1.0  49.0        3.0             1.0         92.5   \n",
       "6              2.0     2.0  19.0        3.0             5.0         59.2   \n",
       "7              2.0     2.0  59.0        1.0             1.0         78.0   \n",
       "10             2.0     1.0  43.0        2.0             4.0        111.8   \n",
       "12             2.0     1.0  37.0        3.0             5.0         99.2   \n",
       "\n",
       "    Exam Completion  \n",
       "ID                   \n",
       "5               1.0  \n",
       "6               1.0  \n",
       "7               1.0  \n",
       "10              1.0  \n",
       "12              1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = dataset['Height (cm)']\n",
    "\n",
    "colnames = list(dataset.columns)\n",
    "colnames.remove('Height (cm)')\n",
    "features = dataset.loc[:,colnames]\n",
    "\n",
    "display(target.describe())\n",
    "display(features.describe())\n",
    "display(features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Side Note: Unit Testing\n",
    "---\n",
    "\n",
    "Using tests can make sure your analysis code is doing what you intended. Some things to check for:\n",
    "\n",
    "* Array size\n",
    "* Data type\n",
    "* Maximum and minimum values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_equal(features.shape[0], target.shape[0],\n",
    "                        'Target and feature shape mismatch')\n",
    "np.testing.assert_equal(features.shape, (5533,7), 'Wrong feature shape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Training, Testing, and Validation\n",
    "===\n",
    "\n",
    "![Train/Test/Validation Split](Images/TrainTestValSplit.png)\n",
    "\n",
    "- **Training Set** - Portion of the data used to train a machine learning algorithm.\n",
    "- **Testing Set** - Portion of the data (usually 10-30%) not used in training, used to evaluate performance.\n",
    "- **Validation Set** - (Optional) Portion of data (usually 10-30%) used for testing during parameter tuning or classifier selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Training, Testing, and Validation (Expanded Notes)\n",
    "===\n",
    "\n",
    "![Train/Test/Validation Split](Images/TrainTestValSplit.png)\n",
    "\n",
    "In order to evaluate our data properly, we need to divide our dataset into training and testing sets. \n",
    "\n",
    "- **Training Set** - A portion of the data, usually a majority, used to train a machine learning classifier. These are the examples that the computer will learn in order to try to predict data labels.\n",
    "- **Testing Set** - A portion of the data, smaller than the training set (usually 10-30%), used to test the accuracy of the machine learning classifier. The computer does not \"see\" this data while learning, but tries to guess the data labels. We can then determine the accuracy of our method by determining how many examples it got correct.\n",
    "- **Validation Set** - (Optional) A third section of data used for parameter tuning or classifier selection. When selecting among many classifiers, or when a classifier parameter must be adjusted (tuned), a this data is used like a test set to select the best parameter value(s). The final performance is then evaluated on the remaining, previously unused, testing set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why split my dataset?\n",
    "---\n",
    "\n",
    "* **The goal of a testing set is not to make the testing accuracy as high as possible!** \n",
    "* The goal is to make your \"real world/target application\" accuracy as high as possible. \n",
    "* The more accurately your test set reflects real-world conditions, the better it will reflect the real-world accuracy.\n",
    "\n",
    "\n",
    "No one cares how good your test-set accuracy is if your product doesn't work when you ship it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Split Dataset\n",
    "---\n",
    "\n",
    "* 30% of data for Test Set\n",
    "* Remaining 70% will be split between training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: (5533, 7)\n",
      "Training dataset size: (3873, 7)\n",
      "Test dataset size: (1660, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(features, target, test_size=0.3)\n",
    "\n",
    "print('Original dataset size: ' + str(features.shape))\n",
    "print('Training dataset size: ' + str(X_trainval.shape))\n",
    "print('Test dataset size: ' + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Another Good Opportunity for Testing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_equal(X_trainval.shape[0], y_trainval.shape[0],\n",
    "                        'Target and feature training shape mismatch')\n",
    "np.testing.assert_equal(X_test.shape[0], y_test.shape[0],\n",
    "                        'Target and feature test shape mismatch')\n",
    "np.testing.assert_equal(X_trainval.shape[0] + X_test.shape[0], \n",
    "                        features.shape[0], 'Incorrect split')\n",
    "np.testing.assert_equal(X_trainval.shape[1], features.shape[1], \n",
    "                        'Wrong number of features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Set the Random State (Optional)\n",
    "---\n",
    "\n",
    "* Set a random seed so that analysis is reproducible.\n",
    "* Could accidentally use a seed that produces unusual results.\n",
    "* Absolutely don't hunt for the best seed!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(features, target, \n",
    "                                                          test_size=0.3,\n",
    "                                                          random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evenly Distribute Examples (Stratification)\n",
    "---\n",
    "\n",
    "* Proportionally divide target/label values between training and testing data when splitting\n",
    "  - Especially important in classification when one class has many fewer examples\n",
    "* For regression tasks, we can create bin labels to help with distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(np.min(target),np.max(target)+0.1, 5)\n",
    "labels = np.digitize(target, bins)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(features, target, \n",
    "                                                          test_size=0.3,\n",
    "                                                          random_state=seed,\n",
    "                                                          stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How to Use Validation Data\n",
    "---\n",
    "\n",
    "Validation data is used to design your machine learning model. \n",
    "Best-performing model on validation data is tested on Test Set to get final accuracy rating. \n",
    "\n",
    "Use to select:\n",
    "* Machine learning algorithm\n",
    "* Any parameters of the algorithm (e.g. SVM C parameter)\n",
    "* Number of features\n",
    "* Feature reduction algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why can't I test all my algorithms on the test set and report that value?\n",
    "---\n",
    "\n",
    "* This is a type of overfitting\n",
    "* By selecting the best model of many, you are biasing results towards good performance on that particular validation data\n",
    "  - Results are likely overly-optimistic about real-world performance\n",
    "* Test set gives a less-biased estimate of model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Splitting Training and Validation Data\n",
    "---\n",
    "\n",
    "Method 1: Split our training/validation data like we split our full dataset  \n",
    "Method 2: Use Crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Single Split\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trainval size: (3873, 7)\n",
      "X_train size: (2711, 7)\n",
      "X_val size: (1162, 7)\n"
     ]
    }
   ],
   "source": [
    "bins = np.linspace(np.min(y_trainval),np.max(y_trainval)+0.1, 5)\n",
    "labels = np.digitize(y_trainval, bins)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, \n",
    "                                                  test_size=0.3, \n",
    "                                                  random_state=seed, \n",
    "                                                  stratify=labels)\n",
    "\n",
    "print('X_trainval size: ' + str(X_trainval.shape))\n",
    "print('X_train size: ' + str(X_train.shape))\n",
    "print('X_val size: ' + str(X_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Crossvalidation\n",
    "---\n",
    "\n",
    "* Continually splitting our dataset makes it smaller\n",
    "  - Want to use as much data as possible for training\n",
    "* Single division makes results likely to change with random state\n",
    "* Solution: crossvalidation\n",
    "  - Divide data into multiple equal sections (called folds)\n",
    "  - Hold one fold out for validation, train on remaining\n",
    "  - Repeat using each fold as validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Crossvalidation Visualized\n",
    "---\n",
    "\n",
    "![Crossvalidation Visual](Images/Crossvalidation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Crossvalidation in Code\n",
    "---\n",
    "\n",
    "Iterator providing index of training and testing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3098,) (775,)\n",
      "(3098,) (775,)\n",
      "(3098,) (775,)\n",
      "(3099,) (774,)\n",
      "(3099,) (774,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Older versions of scikit learn used n_folds instead of n_splits\n",
    "kf = KFold(n_splits=5, random_state=seed)\n",
    "for trainInd, valInd in kf.split(X_trainval):\n",
    "    print(\"%s %s\" % (trainInd.shape, valInd.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Example: Validation for Linear Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Mean Squared Error: 42.9976903151\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "foldMSE = []\n",
    "kf = KFold(n_splits=10, random_state=seed)\n",
    "for trainInd, valInd in kf.split(X_trainval):\n",
    "    X_train = X_trainval.iloc[trainInd,:]\n",
    "    y_train = y_trainval.iloc[trainInd]\n",
    "    X_val = X_trainval.iloc[valInd,:]\n",
    "    y_val = y_trainval.iloc[valInd]\n",
    "    \n",
    "    # Train the classifier and make predictions\n",
    "    regr.fit(X_train, y_train)\n",
    "    pred = regr.predict(X_val)\n",
    "    foldMSE.append(mse(y_val,pred))\n",
    "    \n",
    "print('Average Mean Squared Error: %s' % np.mean(foldMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Stratification\n",
    "---\n",
    "Like with `train_test_split()` we can use stratification to evenly distribute labels among folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Mean Squared Error: 42.9771010149\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "bins = np.linspace(np.min(y_trainval),np.max(y_trainval)+0.1, 5)\n",
    "labels = np.digitize(y_trainval, bins)\n",
    "\n",
    "foldMSE = []\n",
    "kf = StratifiedKFold(n_splits=10, random_state=seed)\n",
    "for trainInd, valInd in kf.split(X_trainval, labels):\n",
    "    X_train = X_trainval.iloc[trainInd,:]\n",
    "    y_train = y_trainval.iloc[trainInd]\n",
    "    X_val = X_trainval.iloc[valInd,:]\n",
    "    y_val = y_trainval.iloc[valInd]\n",
    "    \n",
    "    # Train the classifier and make predictions\n",
    "    regr.fit(X_train, y_train)\n",
    "    pred = regr.predict(X_val)\n",
    "    foldMSE.append(mse(y_val,pred))\n",
    "    \n",
    "print('Average Mean Squared Error: %s' % np.mean(foldMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Feature Scaling and Normalization\n",
    "===\n",
    "\n",
    "* Many algorithms work best (or only) when your features are on a similar scale or normalized to a given range\n",
    "* Helpful for features with unrelated units of different magnitudes\n",
    "  - e.g. 2 bedrooms & 1,000 sq. feet\n",
    "* Calculate on training set, then apply to test/validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Feature Scaling and Normalization (Continued)\n",
    "===\n",
    "\n",
    "* 0-mean and unit-variance\n",
    "  - Can speed up training convergence (e.g. SVMs)\n",
    "  - Required for methods that make decisions based on size of variance (e.g. PCA)\n",
    "* Range [0,1] or [-1,1]\n",
    "  - Prevents saturation in some algorithms\n",
    "    - e.g. Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Applying Feature Scaling\n",
    "---\n",
    "\n",
    "0-mean and unit-variance on a single training/validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Feature Scaling With Crossvalidation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Mean Squared Error: 42.9771010149\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "bins = np.linspace(np.min(y_trainval),np.max(y_trainval)+0.1, 5)\n",
    "labels = np.digitize(y_trainval, bins)\n",
    "\n",
    "foldMSE = []\n",
    "kf = StratifiedKFold(n_splits=10, random_state=seed)\n",
    "for trainInd, valInd in kf.split(X_trainval, labels):\n",
    "    X_train = X_trainval.iloc[trainInd,:]\n",
    "    y_train = y_trainval.iloc[trainInd]\n",
    "    X_val = X_trainval.iloc[valInd,:]\n",
    "    y_val = y_trainval.iloc[valInd]\n",
    "    \n",
    "    # Here we scale the data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    # Train the classifier and make predictions\n",
    "    regr.fit(X_train, y_train)\n",
    "    pred = regr.predict(X_val)\n",
    "    foldMSE.append(mse(y_val,pred))\n",
    "    \n",
    "print('Average Mean Squared Error: %s' % np.mean(foldMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Dimensionality Reduction\n",
    "===\n",
    "\n",
    "Reduce the number of features to keep only the most relevant data\n",
    "\n",
    "Why?\n",
    "* Speed up training\n",
    "* Store less data\n",
    "* Can improve accuracy by getting rid of \"noise\"\n",
    "\n",
    "Methods\n",
    "* Feature Selection\n",
    "* Feature Extraction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Feature selection\n",
    "---\n",
    "\n",
    "Choose a subset of the original features to include\n",
    "\n",
    "**Feature Selection Method Examples:**\n",
    "\n",
    "* SelectKBest: Selects features based on a scoring function (e.g. mutual information)\n",
    "* Recursive Feature Elimination (RFE): Uses machine learning algorithm to remove least important features\n",
    "\n",
    "Examples available in Notebook\n",
    "  \n",
    "scikit learn has a page on [feature selection methods](http://scikit-learn.org/stable/modules/feature_selection.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "SelectKBest\n",
    "---\n",
    "\n",
    "Selects `k` best features based on a scoring function, such as mutual information, chi-squared, or ANOVA F-value\n",
    "  \n",
    "[scikit-learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape: (3487, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "selector = SelectKBest(mutual_info_regression, k=4)\n",
    "selector.fit(X_train, y_train)\n",
    "X_train = selector.transform(X_train)\n",
    "X_val = selector.transform(X_val)\n",
    "print('New shape: ' + str(X_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Which Features Were Kept?\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept Features: Gender, Education, Marital Status, Weight (kg)\n"
     ]
    }
   ],
   "source": [
    "support = selector.get_support()\n",
    "kept = features.columns[support]\n",
    "print('Kept Features: ' + ', '.join(kept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "SelectKBest With Crossvalidation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Mean Squared Error: 44.5497275082\n"
     ]
    }
   ],
   "source": [
    "bins = np.linspace(np.min(y_trainval),np.max(y_trainval)+0.1, 5)\n",
    "labels = np.digitize(y_trainval, bins)\n",
    "\n",
    "foldMSE = []\n",
    "kf = StratifiedKFold(n_splits=10, random_state=seed)\n",
    "for trainInd, valInd in kf.split(X_trainval, labels):\n",
    "    X_train = X_trainval.iloc[trainInd,:]\n",
    "    y_train = y_trainval.iloc[trainInd]\n",
    "    X_val = X_trainval.iloc[valInd,:]\n",
    "    y_val = y_trainval.iloc[valInd]\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    # Select the features\n",
    "    selector = SelectKBest(mutual_info_regression, k=4)\n",
    "    selector.fit(X_train, y_train)\n",
    "    X_train = selector.transform(X_train)\n",
    "    X_val = selector.transform(X_val)\n",
    "    \n",
    "    # Train the classifier and make predictions\n",
    "    regr.fit(X_train, y_train)\n",
    "    pred = regr.predict(X_val)\n",
    "    foldMSE.append(mse(y_val,pred))\n",
    "    \n",
    "print('Average Mean Squared Error: %s' % np.mean(foldMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Recursive Feature Elimination (RFE)\n",
    "---\n",
    "\n",
    "Recursively removes features until the desired number are left using a machine learning algorithm to determine feature importance\n",
    "\n",
    "[scikit-learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Get un-reduced training sets \n",
    "X_train = X_trainval.iloc[trainInd,:]\n",
    "y_train = y_trainval.iloc[trainInd]\n",
    "X_val = X_trainval.iloc[valInd,:]\n",
    "y_val = y_trainval.iloc[valInd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept Features: Gender, Education, Weight (kg), Exam Completion\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "selector = RFE(regr, n_features_to_select=4)\n",
    "selector.fit(X_train, y_train)\n",
    "X_train = selector.transform(X_train)\n",
    "X_val = selector.transform(X_val)\n",
    "\n",
    "support = selector.get_support()\n",
    "kept = features.columns[support]\n",
    "print('Kept Features: ' + ', '.join(kept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "RFE With Crossvalidation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Mean Squared Error: 42.9115611772\n"
     ]
    }
   ],
   "source": [
    "bins = np.linspace(np.min(y_trainval),np.max(y_trainval)+0.1, 5)\n",
    "labels = np.digitize(y_trainval, bins)\n",
    "\n",
    "foldMSE = []\n",
    "kf = StratifiedKFold(n_splits=10, random_state=seed)\n",
    "for trainInd, valInd in kf.split(X_trainval, labels):\n",
    "    X_train = X_trainval.iloc[trainInd,:]\n",
    "    y_train = y_trainval.iloc[trainInd]\n",
    "    X_val = X_trainval.iloc[valInd,:]\n",
    "    y_val = y_trainval.iloc[valInd]\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    # Select the features\n",
    "    regr = linear_model.LinearRegression()\n",
    "    selector = RFE(regr, n_features_to_select=4)\n",
    "    selector.fit(X_train, y_train)\n",
    "    X_train = selector.transform(X_train)\n",
    "    X_val = selector.transform(X_val)\n",
    "    \n",
    "    # Train the classifier and make predictions\n",
    "    regr.fit(X_train, y_train)\n",
    "    pred = regr.predict(X_val)\n",
    "    foldMSE.append(mse(y_val,pred))\n",
    "    \n",
    "print('Average Mean Squared Error: %s' % np.mean(foldMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Feature Extraction\n",
    "---\n",
    "\n",
    "* Project data into a feature space with fewer important dimensions\n",
    "* Creates new features through (typically linear) combinations of original features\n",
    "\n",
    "**Example Feature Extraction Methods:**\n",
    "* Principal Component Analysis (PCA): Use feature variance for projection\n",
    "* Linear Discriminant Analysis (LDA): Supervised projection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Principal Component Analysis (PCA)\n",
    "---\n",
    "* Does not use label information, just variance of features\n",
    "* Creates orthogonal feature set that best explains the feature variance\n",
    "* Make sure to scale/normalize first, or it will just pick the ones with the largest variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Reset our example fold\n",
    "X_train = X_trainval.iloc[trainInd,:]\n",
    "y_train = y_trainval.iloc[trainInd]\n",
    "X_val = X_trainval.iloc[valInd,:]\n",
    "y_val = y_trainval.iloc[valInd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_val = pca.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Interview/Exam', 'Gender', 'Age', 'Education', 'Marital Status',\n",
      "       'Weight (kg)', 'Exam Completion'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Reset our example fold\n",
    "X_train = X_trainval.iloc[trainInd,:]\n",
    "y_train = y_trainval.iloc[trainInd]\n",
    "print(X_train.columns)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "PCA With Crossvalidation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Mean Squared Error: 45.9330535547\n"
     ]
    }
   ],
   "source": [
    "bins = np.linspace(np.min(y_trainval),np.max(y_trainval)+0.1, 5)\n",
    "labels = np.digitize(y_trainval, bins)\n",
    "\n",
    "foldMSE = []\n",
    "kf = StratifiedKFold(n_splits=10, random_state=seed)\n",
    "for trainInd, valInd in kf.split(X_trainval, labels):\n",
    "    X_train = X_trainval.iloc[trainInd,:]\n",
    "    y_train = y_trainval.iloc[trainInd]\n",
    "    X_val = X_trainval.iloc[valInd,:]\n",
    "    y_val = y_trainval.iloc[valInd]\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    # Select the features\n",
    "    pca = PCA(n_components=4, random_state=seed)\n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)\n",
    "    X_val = pca.transform(X_val)\n",
    "    \n",
    "    # Train the classifier and make predictions\n",
    "    regr.fit(X_train, y_train)\n",
    "    pred = regr.predict(X_val)\n",
    "    foldMSE.append(mse(y_val,pred))\n",
    "    \n",
    "print('Average Mean Squared Error: %s' % np.mean(foldMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Reset our example fold\n",
    "X_train = X_trainval.iloc[trainInd,:]\n",
    "y_train = y_trainval.iloc[trainInd]\n",
    "labels_train = labels[trainInd]\n",
    "X_val = X_trainval.iloc[valInd,:]\n",
    "y_val = y_trainval.iloc[valInd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Linear Discriminant Analysis (LDA)\n",
    "---\n",
    "\n",
    "* LDA can be used as both a classificaton algorithm and a supervised dimensionality reduction method\n",
    "* Tries to maximize the separation between classes\n",
    "* Better for classification problems, but we can use it with binned continuous targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alyssa/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# Can also use LDA (which can also be a classifier)\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA(n_components=4)\n",
    "lda.fit(X_train, labels_train)\n",
    "X_train = lda.transform(X_train)\n",
    "X_val = lda.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Side-Note: Collinear Variables\n",
    "---\n",
    "\n",
    "* We got a warning about collinear variables\n",
    "  - 2+ features vary together\n",
    "* If we really want LDA, we should remove collinear variables\n",
    "  - But really, are we sure we want to use a classification method for a regression problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Train/Test/Validation Data Recap\n",
    "===\n",
    "\n",
    "* Never Train on Test (or Validation) Data!\n",
    "  - Easy to do accidentally\n",
    "    + Load data in twice\n",
    "    + Split index mistake so an example is in both train and test\n",
    "    + Doing any transforms or feature selection on the entire dataset before splitting\n",
    "* Use validation data to select best model\n",
    "  - Which algorithm to use\n",
    "  - Which feature reduction technique\n",
    "  - How many features to keep\n",
    "\n",
    "Scikit-Learn has methods to automatically do the entire crossvalidation scoring for you, but I recommend not using them unless you aren't doing **any** feature processing or transforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Algorithm/Model Selection\n",
    "---\n",
    "* Highly dependent on data and problem you want to solve\n",
    "* Use human knowledge to narrow down a range of possibilities\n",
    "* Use model selection with validation for final decision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Algorithm/Model Selection Continued\n",
    "---\n",
    "\n",
    "* Classification vs regression vs clustering\n",
    "  - Based on labels (or lack of labels)\n",
    "* Explainable operation vs \"black box\"\n",
    "  - Explainable: decision trees\n",
    "  - Black box: support vector machines (SVMs), neural networks\n",
    "* Speed of training and/or predictions\n",
    "  - SVM predicts quickly, decision trees more slowly\n",
    "  - Neural networks train slowly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Algorithm/Model Selection Continued\n",
    "---\n",
    "\n",
    "* How complex is your data?\n",
    "  - SVMs and neural networks can handle complex/nonlinear classification\n",
    "* Are there relationships among features?\n",
    "  - Some neural networks can take relationships between features into account\n",
    "    + e.g. Convolutional networks and neighboring pixels in an image\n",
    "  - Some networks have memories\n",
    "    + e.g. Recursive neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example: Compare 4 Models\n",
    "---\n",
    "\n",
    "* Recursive Feature Elimination (RFE) vs Principal Component Analysis (PCA)\n",
    "* 2 vs 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(np.min(y_trainval),np.max(y_trainval)+0.1, 5)\n",
    "labels = np.digitize(y_trainval, bins)\n",
    "\n",
    "# RFE 3 features\n",
    "rfe3mse = []\n",
    "kf = StratifiedKFold(n_splits=10, random_state=seed)\n",
    "for trainInd, valInd in kf.split(X_trainval, labels):\n",
    "    # Get training and validation folds\n",
    "    X_train = X_trainval.iloc[trainInd,:]\n",
    "    y_train = y_trainval.iloc[trainInd]\n",
    "    X_val = X_trainval.iloc[valInd,:]\n",
    "    y_val = y_trainval.iloc[valInd]\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    # Select the features\n",
    "    regr = linear_model.LinearRegression()\n",
    "    selector = RFE(regr, n_features_to_select=3)\n",
    "    selector.fit(X_train, y_train)\n",
    "    X_train = selector.transform(X_train)\n",
    "    X_val = selector.transform(X_val)\n",
    "    \n",
    "    # Train the classifier and make predictions\n",
    "    regr.fit(X_train, y_train)\n",
    "    pred = regr.predict(X_val)\n",
    "    rfe3mse.append(mse(y_val,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# RFE 2 features\n",
    "rfe2mse = []\n",
    "kf = StratifiedKFold(n_splits=10, random_state=seed)\n",
    "for trainInd, valInd in kf.split(X_trainval, labels):\n",
    "    X_train = X_trainval.iloc[trainInd,:]\n",
    "    y_train = y_trainval.iloc[trainInd]\n",
    "    X_val = X_trainval.iloc[valInd,:]\n",
    "    y_val = y_trainval.iloc[valInd]\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    # Select the features\n",
    "    regr = linear_model.LinearRegression()\n",
    "    selector = RFE(regr, n_features_to_select=2)\n",
    "    selector.fit(X_train, y_train)\n",
    "    X_train = selector.transform(X_train)\n",
    "    X_val = selector.transform(X_val)\n",
    "    \n",
    "    # Train the classifier and make predictions\n",
    "    regr.fit(X_train, y_train)\n",
    "    pred = regr.predict(X_val)\n",
    "    rfe2mse.append(mse(y_val,pred))\n",
    "    \n",
    "    \n",
    "# PCA 3 features\n",
    "pca3mse = []\n",
    "kf = StratifiedKFold(n_splits=10, random_state=seed)\n",
    "for trainInd, valInd in kf.split(X_trainval, labels):\n",
    "    X_train = X_trainval.iloc[trainInd,:]\n",
    "    y_train = y_trainval.iloc[trainInd]\n",
    "    X_val = X_trainval.iloc[valInd,:]\n",
    "    y_val = y_trainval.iloc[valInd]\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    # Select the features\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(X_train, y_train)\n",
    "    X_train = pca.transform(X_train)\n",
    "    X_val = pca.transform(X_val)\n",
    "    \n",
    "    # Train the classifier and make predictions\n",
    "    regr.fit(X_train, y_train)\n",
    "    pred = regr.predict(X_val)\n",
    "    pca3mse.append(mse(y_val,pred))\n",
    "    \n",
    "    \n",
    "# PCA 2 features\n",
    "pca2mse = []\n",
    "kf = StratifiedKFold(n_splits=10, random_state=seed)\n",
    "for trainInd, valInd in kf.split(X_trainval, labels):\n",
    "    # Get training and testing folds\n",
    "    X_train = X_trainval.iloc[trainInd,:]\n",
    "    y_train = y_trainval.iloc[trainInd]\n",
    "    X_val = X_trainval.iloc[valInd,:]\n",
    "    y_val = y_trainval.iloc[valInd]\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    # Select the features\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X_train, y_train)\n",
    "    X_train = pca.transform(X_train)\n",
    "    X_val = pca.transform(X_val)\n",
    "    \n",
    "    # Train the classifier and make predictions\n",
    "    regr.fit(X_train, y_train)\n",
    "    pred = regr.predict(X_val)\n",
    "    pca2mse.append(mse(y_val,pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Validation Results\n",
    "---\n",
    "\n",
    "Best performance by RFE with 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE 3 MSE: 45.5156398712\n",
      "RFE 2 MSE: 47.1810928949\n",
      "PCA 3 MSE: 48.6948873689\n",
      "PCA 2 MSE: 48.8546099501\n"
     ]
    }
   ],
   "source": [
    "print('RFE 3 MSE: %s' % np.mean(rfe3mse))\n",
    "print('RFE 2 MSE: %s' % np.mean(rfe2mse))\n",
    "print('PCA 3 MSE: %s' % np.mean(pca3mse))\n",
    "print('PCA 2 MSE: %s' % np.mean(pca2mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Test Results\n",
    "---\n",
    "\n",
    "* Retrain the best model and evaluate on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 45.5156398712\n",
      "Test MSE: 45.6205589445\n"
     ]
    }
   ],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_trainval)\n",
    "X_trainval = scaler.transform(X_trainval)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Select the features\n",
    "regr = linear_model.LinearRegression()\n",
    "selector = RFE(regr, n_features_to_select=3)\n",
    "selector.fit(X_trainval, y_trainval)\n",
    "X_trainval = selector.transform(X_trainval)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# Train the classifier and make predictions\n",
    "regr.fit(X_trainval, y_trainval)\n",
    "pred = regr.predict(X_test)\n",
    "testmse = mse(y_test,pred)\n",
    "\n",
    "print('Validation MSE: %s' % np.mean(rfe3mse))\n",
    "print('Test MSE: %s' % np.mean(testmse))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
